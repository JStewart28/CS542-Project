\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{biblatex}
\addbibresource{references.bib}

\newcommand\todoJason[1]{\todo[author=Jason,color=yellow,inline]{#1}}
\newcommand\todoMichael[1]{\todo[author=Michael,color=green,inline]{#1}}
\newcommand\todoChris[1]{\todo[author=Chris,color=orange,inline]{#1}}

\title{How Super are Super Computers?}
\author{Jason Stewart\\
\textit{jastewart@unm.edu} 
\and
Michael Servilla\\
\textit{chico@unm.edu}
\and
Christopher Leap\\
\textit{cleap@unm.edu}
\date{\today}
}

\begin{document}

\maketitle

\section{Proposal}
\subsection{Question}
How does the compute and communication power of personal laptops compare to that of supercomputers? The motivation for this question is because in theory, supercomputers are just a collection of "normal" computers connected together by a fast network. 
\subsection{Hypothesis}

We hypothesize that:
\begin{enumerate}
    \item The distributions of our benchmark times on a single processor with multiple cores should be equivalent between supercomputers and our laptops, when scaled with the number of processors.
    \item The distribution of benchmark times for laptops should be lower (faster) than the times for a supercomputer using one process per node and multiple processes.
    \item When oversubscribing processors, the distribution of results will be equivalent between the supercomputers and our laptops when scaled per processor.
    \item Compiling our benchmarks using different implementations of MPI (e.g. OpenMPI, MPICH, etc.) will result in statistically-significantly different results, which will vary by which system we are running on.
    \item In cases where we expect the performance between supercomputers and laptops to be equivalent, we will see that the processors' clock speed will be a better predictor of benchmark performance than whether or not the benchmark was run on a supercomputer.
\end{enumerate}

\subsection{Methods}
\begin{enumerate}
    \item Code a low-compute, network intensive program by performing an MPI All-to-all operation amongst many processes. Code a high compute, low communication method by counting prime numbers from zero to one million, splitting the work amongst the number of processes and then performing an MPI Gather. Evaluate the computational performance by measuring time-to-completion on various systems.
    \item Run these benchmarks on a single node on different supercomputers, on multiple nodes with one process per node, and on our personal laptops.
    \item We will test for inequality of distributions using t-tests \cite{ttest}, and equality of distributions using the "two one-sided t-tests" (TOST) procedure \cite{tost}.
\end{enumerate}

\printbibliography

\end{document}


example cite: \cite{cfb_db}


\newpage
\nocite{*}
\bibliographystyle{acm}
\bibliography{references}



Please upload a 2 page, single space, PDF document containing the following information:
- Proposal title
- Team members
Sections:
Introduction. Describe what is the problem that you want to address, why is it important and why it qualifies as a Big Data problem
Data: describe the data that you will use, its source(s), and what is your plan to secure the data in a timely manner. Use at least two data sources. 
Methodology: explain in broad terms the approach or approaches you may consider to solve your problem. This section does not need to be very accurate at this point, you can figure out other approaches as the course continues, but I just want some ideas. 
Contingency plan: if everything fails, what is your plan B? again, it does not need to be accurate or flushed out, I just want to see that you are considering all the angles








\todoBoth{Poke around at databases so we can get data}
\todoMark{ETL Composite DB}
\todoJason{fill out proposed metrics by Friday}




We can pull this data out of the pro database, but it will require writing good queries because it's not readily available to us.


\missingfigure{put some graphs here}


